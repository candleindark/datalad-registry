version: "2.1"  # Compose file format v3 does not support health checks
services:
  web:
    build:
      dockerfile: dev.dockerfile
    depends_on:
      broker:
        condition: service_healthy
      db:
        condition: service_healthy
    ports:
      - "5000:5000"
    environment: &env
      DATALAD_REGISTRY_PASSWORD: "$DATALAD_REGISTRY_PASSWORD"
      DATALAD_REGISTRY_INSTANCE_PATH: "/app/instance"
      DATALAD_REGISTRY_DATASET_CACHE: "/app/instance/cache"
      DATALAD_REGISTRY_LOG_LEVEL: "DEBUG"

      POSTGRES_PASSWORD: "${POSTGRES_PASSWORD}"

      RABBITMQ_DEFAULT_USER: "user"
      RABBITMQ_DEFAULT_PASS: "$RABBITMQ_DEFAULT_PASS"

      FLASK_APP: "datalad_registry.factory:create_app"

      CELERY_BROKER_URL: "amqp://user:$RABBITMQ_DEFAULT_PASS@broker:5672"
      CELERY_RESULT_BACKEND_URL: "redis://backend:6379"

      DATALAD_REGISTRY_POSTGRES_HOST: db

    command: [
      "bash", "-c",
      "pip3 install -e . && flask init-db && flask run --host=0.0.0.0"
    ]
    volumes:
      - ./:/app
      - ${DL_REGISTRY_INSTANCE_PATH}:/app/instance

  worker:
    build:
      dockerfile: dev.dockerfile
    depends_on:
      broker:
        condition: service_healthy
      db:
        condition: service_healthy
    command: [
      "bash", "-c",
      "pip3 install -e . && celery -A datalad_registry.runcelery.celery worker --loglevel DEBUG --pool, prefork"
    ]
    volumes:
      - ./:/app
      - ${DL_REGISTRY_INSTANCE_PATH}:/app/instance
    environment:
      <<: *env
    healthcheck:
      test: [ "CMD-SHELL", "celery -A datalad_registry.runcelery.celery status --timeout 1 --json | grep -q pong" ]
      interval: 5s
      timeout: 3s
      retries: 10

  # Monitor for Celery service
  monitor:
    build:
      dockerfile: dev.dockerfile
    depends_on:
      broker:
        condition: service_healthy
      worker:
        condition: service_healthy
    environment:
      <<: *env
      FLOWER_BROKER_API: "http://user:$RABBITMQ_DEFAULT_PASS@broker:15672/api/"
      FLOWER_PERSISTENT: "True"
      FLOWER_DB: "/app/instance/monitor/flower"
      FLOWER_STATE_SAVE_INTERVAL: "1000"  # In milliseconds
      FLOWER_ENABLE_EVENTS: "True"
      FLOWER_BASIC_AUTH: "$FLOWER_BASIC_AUTH"
    ports:
      - "127.0.0.1:5555:5555"
    command: [
      "bash", "-c",
      "pip3 install -e . && celery --app datalad_registry.runcelery.celery flower"
    ]
    volumes:
      - ./:/app
      - ${DL_REGISTRY_INSTANCE_PATH}/monitor:/app/instance/monitor
    healthcheck:
      test: RESPONSE=$$(curl -s http://localhost:5555/healthcheck); if [ "$$RESPONSE" = "OK" ]; then exit 0; else exit 1; fi
      interval: 30s
      timeout: 10s
      retries: 3

  # TODO: Currently, there is no job to be scheduled.
  #   Disable this to make debugging easier.
  #   Once there is a job to be scheduled, we can uncomment this to enable the scheduler
  #  scheduler:
  #    build: .
  #    depends_on:
  #      broker:
  #        condition: service_healthy
  #    command: [
  #      celery, -A, datalad_registry.runcelery.celery,
  #      beat,
  #      --loglevel, DEBUG,
  #      -s, /app/instance/celerybeat-schedule
  #    ]
  #    volumes:
  #      - ${DL_REGISTRY_INSTANCE_PATH}:/app/instance
  #    environment:
  #      <<: *env

  broker:
    image: docker.io/rabbitmq:3-management
    hostname: dlreg-broker
    environment:
      RABBITMQ_DEFAULT_USER: "user"
      RABBITMQ_DEFAULT_PASS: "$RABBITMQ_DEFAULT_PASS"
    ports:
      - "127.0.0.1:5672:5672"
      - "127.0.0.1:15672:15672"
    volumes:
      - ${DL_REGISTRY_INSTANCE_PATH}/broker/home:/var/lib/rabbitmq
    healthcheck: # https://www.rabbitmq.com/monitoring.html#health-checks
      test: rabbitmq-diagnostics -q ping
      interval: 30s
      timeout: 30s
      retries: 3

  # Result backend for Celery
  backend:
    image: docker.io/redis:7
    ports:
      - "127.0.0.1:6379:6379"

  db:
    image: docker.io/postgres:latest
    environment:
      POSTGRES_DB: dlreg
      POSTGRES_USER: dlreg
      POSTGRES_PASSWORD: "${POSTGRES_PASSWORD}"
      POSTGRES_INITDB_ARGS: --encoding utf8 --locale C
    ports:
      - "127.0.0.1:5432:5432"
    userns_mode: "keep-id"  # This has an effect only after podman-compose 1.0.3 possibly
      # See https://github.com/containers/podman-compose/issues/166
      # for details.
      # For podman-compose 1.0.3 or earlier, use
      # `PODMAN_USERNS=keep-id podman-compose up`

    volumes:
      - ${DL_REGISTRY_DB_DATA_PATH}:/var/lib/postgresql/data
    healthcheck:
      test: [ "CMD", "pg_isready", "-U", "dlreg" ]
      interval: 7s
      timeout: 3s
      retries: 5
